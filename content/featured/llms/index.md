---
date: '3'
title: 'Transformer from Scratch + Adapter Tuning'
cover: './transformer.png'
github: 'https://github.com/VridhiJ/LLMs'
tech:
  - PyTorch
  - LoRA
  - IA3
  - Quantization
  - GLUE
external: ''
---

Built a transformer from scratch in PyTorch with multi-head attention and positional encoding.
Fine-tuned LLMs using LoRA and IA3 adapters, reducing trainable parameters by 99%.
Compressed models by 75% using quantization while preserving GLUE benchmark accuracy.
