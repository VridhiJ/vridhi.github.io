---
date: '3'
title: 'Transformer from Scratch + Adapter Tuning'
cover: './transformer.png'
github: 'https://github.com/VridhiJ/LLMs/tree/main'
tech:
  - PyTorch
  - LoRA
  - IA3
  - Quantization
  - GLUE
  cta: ''
---

Built a transformer model from scratch using PyTorch, including multi-head attention and positional encoding for text classification.

Fine-tuned large language models using **LoRA** and **IA3** adapters, reducing trainable parameters by **99%** without sacrificing accuracy on GLUE benchmarks.

Achieved **75% compression** using quantization-aware training and post-training quantization, maintaining competitive downstream performance.
